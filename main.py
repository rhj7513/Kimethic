import streamlit as st
import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
from tensorflow.keras import layers, models
import io
import soundfile as sf
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout='wide', page_title='EthicApp')

# ì‚¬ì´ë“œë°” ë©”ë‰´ ì„ íƒ
menu = st.sidebar.radio("Menu", ["í™ˆ", "AI ìœ¤ë¦¬ ê°œìš”", "ë”¥í˜ì´í¬ ìŒì„±", "ì°¸ê³  ìë£Œ"])

# YouTube ì˜ìƒ ë§í¬
url = 'https://www.youtube.com/watch?v=XyEOEBsa8I4'

# í•©ì„± ì˜¤ë””ì˜¤ ìƒì„± í•¨ìˆ˜
def generate_synthetic_audio(is_real=True, duration=3, sr=22050):
    t = np.linspace(0, duration, int(sr * duration))
    if is_real:
        # ìì—°ìŠ¤ëŸ¬ìš´ ì£¼íŒŒìˆ˜ë¥¼ ê°€ì§„ ì§„ì§œ ìŒì„± ëª¨ì‚¬
        freq = 200 + 100 * np.sin(2 * np.pi * 0.1 * t)
        audio = 0.5 * np.sin(2 * np.pi * freq * t)
    else:
        # ì¸ìœ„ì  íŒ¨í„´ê³¼ ë…¸ì´ì¦ˆë¥¼ ë”í•œ ë”¥í˜ì´í¬ ìŒì„± ëª¨ì‚¬
        freq = 200 + 50 * np.sin(2 * np.pi * 0.2 * t)
        audio = 0.5 * np.sin(2 * np.pi * freq * t) + 0.1 * np.random.randn(len(t))
    return audio, sr

# MFCC íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜
def extract_mfcc(audio, sr, n_mfcc=13):
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfcc.T, axis=0)

# ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ ì¶”ì¶œ í•¨ìˆ˜
def extract_spectrogram(audio, sr, n_mels=128, hop_length=512):
    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, hop_length=hop_length)
    S_dB = librosa.power_to_db(S, ref=np.max)
    S_dB = S_dB[:, :128]
    if S_dB.shape[1] < 128:
        S_dB = np.pad(S_dB, ((0, 0), (0, 128 - S_dB.shape[1])), mode='constant')
    return S_dB

# ì˜¤ë””ì˜¤ ì¬ìƒ í”Œë ˆì´ì–´ ìƒì„± í•¨ìˆ˜
def get_audio_player(audio, sr):
    buffer = io.BytesIO()
    sf.write(buffer, audio, sr, format='WAV')
    audio_base64 = base64.b64encode(buffer.getvalue()).decode()
    audio_html = f'<audio controls><source src="data:audio/wav;base64,{audio_base64}" type="audio/wav"></audio>'
    return audio_html

# ê°„ë‹¨í•œ CNN ëª¨ë¸ êµ¬ì„±
def build_cnn_model(input_shape=(128, 128, 1)):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì•± ì‹¤í–‰ í•¨ìˆ˜
def run_deepfake_detection():
    st.title("ğŸ™ï¸ ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì›¹ì•±")
    st.header("íŠœí† ë¦¬ì–¼: ë”¥í˜ì´í¬ ìŒì„± íƒì§€ ì´í•´í•˜ê¸°")
    st.markdown("""
    ì´ ì›¹ì•±ì€ ê³ ë“±í•™ìƒì„ ëŒ€ìƒìœ¼ë¡œ AIê°€ **ì§„ì§œ ìŒì„±**ê³¼ **ë”¥í˜ì´í¬ ìŒì„±**ì„ ì–´ë–»ê²Œ êµ¬ë³„í•˜ëŠ”ì§€ í•™ìŠµí•˜ë„ë¡ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.
    ì•„ë˜ íŠœí† ë¦¬ì–¼ì„ ë”°ë¼ë³´ì„¸ìš”:
    
    ### ë”¥í˜ì´í¬ ìŒì„±ì´ë€?
    - **ì§„ì§œ ìŒì„±**: ìœ íŠœë¸Œ ì¸í„°ë·°, íŒŸìºìŠ¤íŠ¸, ë‰´ìŠ¤ ë“±ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ìŒëœ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ì…ë‹ˆë‹¤.
    - **ë”¥í˜ì´í¬ ìŒì„±**: AIê°€ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ë¥¼ ëª¨ë°©í•´ ë§Œë“¤ì–´ë‚¸ ìŒì„±ì…ë‹ˆë‹¤.
    - **ì™œ ì¤‘ìš”í• ê¹Œìš”?**: ë”¥í˜ì´í¬ëŠ” ê°€ì§œ ë‰´ìŠ¤ë‚˜ í—ˆìœ„ ì •ë³´ë¥¼ í¼ëœ¨ë¦´ ë•Œ ì´ìš©ë  ìˆ˜ ìˆì–´ ìœ„í—˜í•©ë‹ˆë‹¤. ì´ ì•±ì€ AIê°€ ì–´ë–»ê²Œ ì´ë¥¼ íƒì§€í•  ìˆ˜ ìˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
    
    ### ì‚¬ìš© ë°©ë²•
    - ìŒì„±ì„ ìƒì„±í•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš”.
    - ì²­ì·¨í•˜ê³  ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ í™•ì¸í•˜ì„¸ìš”.
    - **[í•™ìŠµ í›„ ë¶„ë¥˜]** ë²„íŠ¼ì„ ëˆ„ë¥´ê³  AI ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ì„¸ìš”.
    - í† ë¡  ì§ˆë¬¸ì„ í†µí•´ AI ìœ¤ë¦¬ì™€ ì±…ì„ì— ëŒ€í•´ í•¨ê»˜ ìƒê°í•´ë³´ì„¸ìš”.
    """)
    
    # 1ë‹¨ê³„: ìŒì„± ìƒì„± ë˜ëŠ” ì—…ë¡œë“œ
    st.subheader("1ë‹¨ê³„: ìŒì„± ìƒì„± ë˜ëŠ” ì—…ë¡œë“œ")
    col1, col2 = st.columns(2)

    with col1:
        if st.button("ì§„ì§œ ìŒì„± ìƒì„±"):
            audio, sr = generate_synthetic_audio(is_real=True)
            st.session_state['audio'] = audio
            st.session_state['sr'] = sr
            st.session_state['is_real'] = True
            st.markdown("**âœ”ï¸ ì§„ì§œ ìŒì„± ìƒ˜í”Œ ìƒì„±ë¨**")
            st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    with col2:
        if st.button("ê°€ì§œ ìŒì„± ìƒì„±"):
            audio, sr = generate_synthetic_audio(is_real=False)
            st.session_state['audio'] = audio
            st.session_state['sr'] = sr
            st.session_state['is_real'] = False
            st.markdown("**âœ”ï¸ ê°€ì§œ ìŒì„± ìƒ˜í”Œ ìƒì„±ë¨**")
            st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    uploaded_file = st.file_uploader("ë˜ëŠ” WAV íŒŒì¼ ì—…ë¡œë“œ", type=["wav"])
    if uploaded_file:
        audio, sr = librosa.load(uploaded_file, sr=22050)
        st.session_state['audio'] = audio
        st.session_state['sr'] = sr
        st.session_state['is_real'] = None
        st.markdown("**âœ”ï¸ ì—…ë¡œë“œëœ ìŒì„±**")
        st.markdown(get_audio_player(audio, sr), unsafe_allow_html=True)

    # 2ë‹¨ê³„: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì‹œê°í™”
    if 'audio' in st.session_state:
        st.subheader("2ë‹¨ê³„: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ í™•ì¸")
        fig, ax = plt.subplots()
        S = librosa.feature.melspectrogram(y=st.session_state['audio'], sr=st.session_state['sr'])
        S_dB = librosa.power_to_db(S, ref=np.max)
        librosa.display.specshow(S_dB, sr=st.session_state['sr'], x_axis='time', y_axis='mel', ax=ax)
        ax.set(title='Mel ìŠ¤í™íŠ¸ë¡œê·¸ë¨')
        st.pyplot(fig)

    # 3ë‹¨ê³„: AI í•™ìŠµ ë° ë¶„ë¥˜
    st.subheader("3ë‹¨ê³„: AIë¡œ ë¶„ë¥˜í•˜ê¸°")
    if st.button("í•™ìŠµ í›„ ë¶„ë¥˜ ì‹¤í–‰"):
        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
        X_rf, y_rf = [], []
        for _ in range(50):
            ra, sr = generate_synthetic_audio(is_real=True)
            fa, _ = generate_synthetic_audio(is_real=False)
            X_rf.append(extract_mfcc(ra, sr))
            X_rf.append(extract_mfcc(fa, sr))
            y_rf.append(1)
            y_rf.append(0)

        X_rf = np.array(X_rf)
        y_rf = np.array(y_rf)

        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨
        rf_model = RandomForestClassifier(n_estimators=100)
        rf_model.fit(X_rf, y_rf)

        # ìŒì„± ë°ì´í„° ì²˜ë¦¬
        mfcc = extract_mfcc(st.session_state['audio'], st.session_state['sr'])
        pred_rf = rf_model.predict([mfcc])

        st.write(f"ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡: {'ì§„ì§œ' if pred_rf[0] == 1 else 'ê°€ì§œ'} ìŒì„±")

# ë©”ë‰´ ì²˜ë¦¬
if menu == "í™ˆ":
    st.title('Ethic is good for us')
    content_col, tips_col = st.columns([4, 1])

    with content_col:
        st.subheader("AI Ethics and Responsibility")
        st.video(url)
        st.write("""
        ì¸ê³µì§€ëŠ¥(AI)ì€ í˜„ëŒ€ ì‚¬íšŒë¥¼ ë³€í™”ì‹œí‚¤ëŠ” í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.  
        ê·¸ëŸ¬ë‚˜ AIì˜ ì‚¬ìš©ì—ëŠ” ìœ¤ë¦¬ì  ê³ ë ¤ê°€ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•˜ë©°, ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì›ì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
        - **ê³µì •ì„± (Fairness)**  
        - **ì±…ì„ì„± (Accountability)**  
        - **íˆ¬ëª…ì„± (Transparency)**  
        - **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ (Privacy Protection)**

        **AI ìœ¤ë¦¬ì  ì‚¬ê³ **ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ì˜ê²¬ì„ ì•„ë˜ì— ë‚¨ê²¨ì£¼ì„¸ìš”.
        """)
        
        # ì˜ê²¬ ì œì¶œ í¼
        user_opinion = st.text_area("ì—¬ëŸ¬ë¶„ì˜ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”:")
        if st.button("ì œì¶œ"):
            if user_opinion:
                with open("data.txt", "a") as file:
                    file.write(f"{user_opinion}\n")
                st.success("ì˜ê²¬ì´ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì˜ê²¬ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with tips_col:
        st.subheader("AI ìœ¤ë¦¬ ê°œìš”")
        st.markdown("""
        1. **ê³µì •ì„± (Fairness)**: AIê°€ í¸í–¥ëœ ê²°ì •ì„ ë‚´ë¦¬ì§€ ì•Šë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.
        2. **ì±…ì„ì„± (Accountability)**: AI ì‹œìŠ¤í…œì˜ ê²°ì •ì„ ì¸ê°„ì´ ì±…ì„ì ¸ì•¼ í•©ë‹ˆë‹¤.
        3. **íˆ¬ëª…ì„± (Transparency)**: AI ì‹œìŠ¤í…œì˜ ë™ì‘ ì›ë¦¬ë¥¼ ëª…í™•íˆ í•´ì•¼ í•©ë‹ˆë‹¤.
        4. **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ (Privacy Protection)**: AIëŠ” ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•´ì•¼ í•©ë‹ˆë‹¤.
        """)

elif menu == "AI ìœ¤ë¦¬ ê°œìš”":
    st.write("AI ìœ¤ë¦¬ ì›ì¹™ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ë‹¤ë©´, ìœ„ì˜ ì„¤ëª…ì„ ì°¸ê³ í•˜ì„¸ìš”.")

elif menu == "ë”¥í˜ì´í¬ ìŒì„±":
    run_deepfake_detection()

elif menu == "ì°¸ê³  ìë£Œ":
    st.write("ì°¸ê³  ìë£Œ ì„¹ì…˜ì…ë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œ ë° ë§í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
